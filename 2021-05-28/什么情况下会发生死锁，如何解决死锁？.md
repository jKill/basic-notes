## 什么情况下会发生死锁，如何解决死锁？
> 死锁可能出现在在所有使用锁的场景，包括应用内线程之间，微服务之间，数据库内部锁等等。以下仅讨论MySQL数据库的死锁。

### 会出现死锁的情况
产生死锁的4个必要条件：

- 互斥：资源一次只允许一个session访问，其他session需要等待正在访问的事务结束。
- 占有且等待：session占用资源A，并且等待着另一个资源B。
- 不可抢占：已经被获得的资源，不可以被另一个session抢占。
- 循环等待：session1等待session2，session2等待session3，session3等待session1，构成一个闭合的环形等待链。

举个例子，一个session持有锁A，等待获得锁B，但锁B的持有者在等待获得锁A。两个互相等待的session形成一个闭合的“等待圈”，互相阻塞。实际场景可能会有更多的seesion，但只要形成闭合的“等待圈”，都会死锁。
### 如何解决死锁
通用的死锁解决方案是破坏死锁4个必要条件之一，对于MySQL数据库而言，需要破坏前3个条件的场景较少，所以这里只讨论破坏循环等待这一条件。MySQL从5.6开始默认会自动检测死锁，尽量回滚其中较小的一个事务。就是通过破坏循环等待来解决的。为了尽可能减少和解决死锁，MySQL官方文档给出了以下建议：

- 使用事务（行锁）代替锁表。
- insert或update尽可能使用小事务，保证事务不会太长，减少事务间冲突。
- 不同的事务更新更新多个表或者非常多行数据的时候，尽量保证每一个事务以相同的顺序操作数据。
- 在有锁操作（如```select ... for update```或者```update ... where```）的字段上创建索引。事务扫描的行数变少，锁的粒度也更小，使用```explain select```确定合适的索引。
- 使用```SHOW ENGINE INNODB STATUS```查看最近的一个死锁原因。
- 如果频繁出现死锁，开启```innodb_print_all_deadlocks```输出所有死锁（不仅仅是最近的一个）的信息到MySQL error log。debug结束后再恢复禁用。
- 需要有重试机制。事务因为死锁而回滚并不罕见，也不危险，重试即可。
- 执行完相关的数据操作后，马上提交事务，减少冲突的可能性。尤其避免在一个打开的mysql session里，执行一个事务而不提交。
- 如果使用“锁定读”（locking read）如select ... for update或者select ... for share，尝试用更低的隔离级别（如READ COMMITTED）。（因为隔离级别会影响读操作的行为，而不会影响写操作，而死锁是因为写操作出现的）
- 尽可能不用锁
- 如果没有其他的方法了，使用表级锁来序列化事务。表锁能防止表的并发更新，避免系统繁忙的时候死锁。

### 优化
死锁不但会阻塞系统，也会对性能造成严重影响。在高并发系统里，死锁检测会导致多个线程等待一个锁，严重影响性能。每个新来的被堵住的线程，都要判断会不会由于自己的加入导致死锁，这个操作的时间复杂度是O(n)。从总体来看，所有线程的总时间复杂度是O(n^2)。即使最终检测的结果是没有死锁，但是检测期间要消耗大量的CPU资源。所以，就会看到CPU利用率很高，每秒却执行不了几个事务。

- 方案一：关闭死锁检测。设置```innodb_deadlock_detect```为off，关闭死锁检测。然后设置```innodb_lock_wait_timeout```超时回滚来在出现死锁时回滚事务。但是，这个值默认50s，等待这么长的时间对大多数业务来说都是不可接受的。设置更小的值，比如1s，又有可能会误伤正常的锁等待。所以，往往很难界定合适的大小，是对业务有损的方案。
- 方案二：控制并发度（难度较高版，需要数据库专家）。对于相同行的更新，在进入Innodb引擎之前排队。这样Innodb就不会进行大量的死锁检查了。可以在中间件或者做在MySQL里（需要有能修改MySQL源码能力）
- 方案三：控制并发度（简单版）。如果没有数据库专家，可以通过改造表实现，将一行改成逻辑上的多行。比如一个电商系统，其中一个商品的库存还剩1000个，将这1000个库存分成10行存储，每行100个库存。并且分配不同id方便哈希。扣减库存时，把客户端哈希到各个的库存行里。这样冲突概率降低到了原来的1/10，减少了死锁检测的CPU消耗。